#!/bin/sh

set -e
set -u
set -o pipefail

# load org and project from repository if exists,
# if not, set them as a random string
if [ -e ".fuseml/_project" ]; then
    export ORG=$(cat .fuseml/_org)
    export PROJECT=$(cat .fuseml/_project)
else
    export ORG=$(tr -dc a-z0-9 </dev/urandom | head -c 6 ; echo '')
    export PROJECT=$(tr -dc a-z0-9 </dev/urandom | head -c 6 ; echo '')
fi
export S3_ENDPOINT=${MLFLOW_S3_ENDPOINT_URL/*:\/\//}


mc alias set minio ${MLFLOW_S3_ENDPOINT_URL} ${AWS_ACCESS_KEY_ID} ${AWS_SECRET_ACCESS_KEY}
model_bucket="minio${FUSEML_MODEL//s3:\//}"

export PROTOCOL_VERSION="v1"
export PREDICTOR=${FUSEML_PREDICTOR}
if [ "${PREDICTOR}" = "auto" ]; then
    if ! mc stat ${model_bucket}/MLmodel &> /dev/null ; then
        echo "No MLmodel found, cannot auto detect predictor"
        exit 1
    fi

    PREDICTOR=$(mc cat ${model_bucket}/MLmodel | awk -F '.' '/loader_module:/ {print $2}')
fi

isvc="${ORG}-${PROJECT}"
case $PREDICTOR in
    # kfserving expects the tensorflow model to be under a numbered directory,
    # however mlflow saves the model under 'tfmodel', so if there is no directory
    # named '1', create it and copy the tensorflow model to it.
    tensorflow)
        if [ "$(mc find ${model_bucket} --name 1)" = "" ]; then
            mc cp -r ${model_bucket}/tfmodel/ ${model_bucket}/1
        fi
        export RUNTIME_VERSION=$(mc cat ${model_bucket}/requirements.txt | awk -F '=' '/tensorflow/ {print $3}')
        prediction_url_path="${isvc}:predict"
        ;;
    # kfserving expects the sklearn model file as model.joblib however mlflow
    # saves the model as model.pkl, so if there is no model.joblib, create a
    # copy named model.joblib from model.pkl
    sklearn)
        if ! mc ls ${model_bucket} | grep -q "model.joblib"; then
            mc cp ${model_bucket}/model.pkl ${model_bucket}/model.joblib
        fi
        export PROTOCOL_VERSION="v2"
        prediction_url_path="${isvc}/infer"
        ;;
esac

envsubst < /root/template.sh | kubectl apply -f -


kubectl wait --for=condition=Ready --timeout=600s inferenceservice/${isvc}
prediction_url="$(kubectl get inferenceservice/${isvc} -o jsonpath='{.status.url}')/${PROTOCOL_VERSION}/models/${prediction_url_path}"
printf "${prediction_url}" > /tekton/results/${TASK_RESULT}

# Now, register the new application within fuseml

inside_metadata=""
first_resource=1
envsubst < /root/template.sh | while read line
do
  if echo $line | grep -q '^[ ]*kind'; then
      inside_metadata=""
      if [[ $first_resource == 0 ]] ; then
          echo -n ", " >> /tmp/resources.json
      else
          first_resource=0
      fi
      echo -n "{$line" | sed -E 's/([^ \t:{]+)/"\1"/g' >> /tmp/resources.json
  fi
  if echo $line | grep -q '^[ ]*metadata:' ; then
      inside_metadata="yes"
  fi
  if echo $line | grep -q '^[ ]*name:' && [[ -n $inside_metadata ]] ; then
      echo -n ", $line}" | sed -E 's/([^ \t:,}]+)/"\1"/g' >> /tmp/resources.json
  fi
done

resources=$(cat /tmp/resources.json | tr -s '"')
rm /tmp/resources.json

curl -X POST -H "Content-Type: application/json"  http://fuseml-core.fuseml-core.svc.cluster.local:80/applications -d "{\"name\":\"$isvc\",\"description\":\"Application generated by $FUSEML_ENV_WORKFLOW_NAME workflow\", \"type\":\"predictor\",\"url\":\"$prediction_url\",\"workflow\":\"$FUSEML_ENV_WORKFLOW_NAME\", \"k8s_namespace\": \"$FUSEML_ENV_WORKFLOW_NAMESPACE\", \"k8s_resources\": [ $resources ]}"
